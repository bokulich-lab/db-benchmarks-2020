{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Seqs & Taxonomy by Processing Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impact of step wise processing per step.\n",
    "\n",
    "Ultimately we'd like to know what the effect of processing has on our sequene and taxonomy evaluations. Many of the files we need have already been made via the notebook `02-SILVA-Benchmark-prep.ipynb` and we'll continue by following the flowchart below:\n",
    "\n",
    "<img src=\"flowchart-evals-by-step.png\">\n",
    "\n",
    "We'll use the files from the following path for input: \n",
    "\n",
    "`/home/mrobeson/projects/rescript_benchmarks/ref_dbs/silva-138/silva-138-nr99-default-noeuks`\n",
    "\n",
    "The files we'll be using from the above path are those in the 'white' boxes. Everything else in 'yellow' we'll do here via the QIIME 2 API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import getcwd, listdir, chdir, mkdir, path\n",
    "import pandas as pd\n",
    "import qiime2 as q2\n",
    "from qiime2.plugins import rescript, taxa, feature_classifier\n",
    "import glob\n",
    "#from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mwd = '/home/mrobeson/projects/rescript_benchmarks'\n",
    "refdb = mwd + '/ref_dbs/silva-138'\n",
    "bench = mwd + '/benchmarks/silva-138'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = refdb + '/silva-138-nr99-default-noeuks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mrobeson/projects/rescript_benchmarks/ref_dbs/silva-138/silva-138-nr99-default-noeuks'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(wd)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial setup\n",
    "\n",
    "We never made a file in which we only keep the good labels using the default mode with `uniq` dereplication. We'll make those files here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import existing NR99 files\n",
    "seqs_derep = q2.Artifact.load('silva-nr99-default-noeuks-derep-seqs.qza')\n",
    "tax_derep = q2.Artifact.load('silva-nr99-default-noeuks-derep-taxa.qza')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_taxa = 's__unidentified,hloroplast,itochondria,s__uncultured,s__uncultivated,etagenome,andidatus,ryza_sativa,_bacterium,_proteobacterium,manure,arctic,marine,water,gut,symbiont,oral,lake,sea,microbial_mat,glacial,drainage,thermal_vent,nrichment,synthetic,candidate,clone,mineralizing,swine,isolate,aerobic,hot_spring,halophilic,gas_vacuolate'\n",
    "exclude_taxa_list = exclude_taxa.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'silva-nr99-default-noeuks-derep-seqs-gl.qza'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exclude sequences that contain unidentified / poor taxonomy labels, then save.\n",
    "seqs_goodlabels, = taxa.actions.filter_seqs(sequences = seqs_derep,\n",
    "                                            taxonomy = tax_derep,\n",
    "                                            exclude = exclude_taxa,\n",
    "                                            mode='contains')\n",
    "seqs_goodlabels.save('silva-nr99-default-noeuks-derep-seqs-gl.qza')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter taxa\n",
    "\n",
    "Used API to filter taxa, as the only way to do this, is with a list of feature ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filt_taxa(seq_infile, tax_infile, tax_outfile):\n",
    "    seqs = q2.Artifact.load(seq_infile)\n",
    "    tax = q2.Artifact.load(tax_infile)\n",
    "    feature_ids = [feature_id for feature_id in seqs.view(pd.Series).index]\n",
    "    ids = pd.Index(feature_ids, name='Feature ID')\n",
    "    ids_to_keep = q2.Metadata(pd.DataFrame(index=ids))\n",
    "    tax_goodlabels, = rescript.actions.filter_taxa(taxonomy=tax, ids_to_keep=ids_to_keep)\n",
    "    tax_goodlabels.save(tax_outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Base No Euks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input features: 510984\n",
      "Output features: 452173\n"
     ]
    }
   ],
   "source": [
    "# No Euks, yes there is a typo in the name (i.e. \"noeuks-noeuks\") from when I first made these files.\n",
    "# I propagatd them through all downstream outputs so we know these files \"belong together\".\n",
    "filt_taxa('silva-nr99-default-noeuks-noeuks-seqs.qza', \n",
    "          'silva-nr99-default-noeuks-parsed-taxonomy.qza', \n",
    "          'silva-nr99-default-noeuks-noeuks-taxa.qza')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Culled Seqs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input features: 510984\n",
      "Output features: 429812\n"
     ]
    }
   ],
   "source": [
    "# Culled Seqs\n",
    "filt_taxa('silva-nr99-default-noeuks-culled-seqs.qza', \n",
    "          'silva-nr99-default-noeuks-parsed-taxonomy.qza', \n",
    "          'silva-nr99-default-noeuks-culled-taxa.qza')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter Seqs Length by Taxon**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input features: 510984\n",
      "Output features: 429812\n"
     ]
    }
   ],
   "source": [
    "# Filt SeqLength by Taxon\n",
    "filt_taxa('silva-nr99-default-noeuks-filt-seqs.qza', \n",
    "          'silva-nr99-default-noeuks-parsed-taxonomy.qza', \n",
    "          'silva-nr99-default-noeuks-filt-taxa.qza')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** ^^ Filtering by different lengths did not remove any additional reads. Indicating many of the short reads also contained homopolymers and/or ambiguous bases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**derep uniq**\n",
    "\n",
    "No need to run `filter-taxa` for the dereplicated data as this is output by `rescript dereplicate`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**remove unclassified / poor labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input features: 510984\n",
      "Output features: 101990\n"
     ]
    }
   ],
   "source": [
    "# Filt by removing unclassified / poor labels.\n",
    "filt_taxa('silva-nr99-default-noeuks-derep-seqs-gl.qza', \n",
    "          'silva-nr99-default-noeuks-parsed-taxonomy.qza', \n",
    "          'silva-nr99-default-noeuks-derep-taxa-gl.qza')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input features: 278221\n",
      "Output features: 52103\n"
     ]
    }
   ],
   "source": [
    "# Filt by removing unclassified / poor labels from v4.\n",
    "filt_taxa('silva-nr99-default-noeuks-derep-seqs-515-806-gl.qza', \n",
    "          'silva-nr99-default-noeuks-derep-taxa-515-806.qza', \n",
    "          'silva-nr99-default-noeuks-derep-taxa-515-806-gl.qza')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval Taxa & Seqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full length only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mSaved Visualization to: NR99-proc-steps-evaltax.qzv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "! qiime rescript evaluate-taxonomy \\\n",
    "    --i-taxonomies silva-nr99-default-noeuks-noeuks-taxa.qza \\\n",
    "                   silva-nr99-default-noeuks-culled-taxa.qza \\\n",
    "                   silva-nr99-default-noeuks-filt-taxa.qza \\\n",
    "                   silva-nr99-default-noeuks-derep-taxa.qza \\\n",
    "                   silva-nr99-default-noeuks-derep-taxa-gl.qza \\\n",
    "    --p-labels 'Base' 'Culled' 'LengFiltByTax' 'DereplicateUniq' 'NoAmbigLabels' \\\n",
    "    --p-rank-handle-regex \"^[dkpcofgs]__\" \\\n",
    "    --o-taxonomy-stats 'NR99-proc-steps-evaltax.qzv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><img onload=\"(function(div, url){\n",
       "if (typeof require !== 'undefined') {\n",
       "    var baseURL = require.toUrl('').split('/').slice(0, -2).join('/');\n",
       "} else {\n",
       "    var baseURL = JSON.parse(\n",
       "        document.getElementById('jupyter-config-data').innerHTML\n",
       "    ).baseUrl.slice(0, -1);\n",
       "}\n",
       "url = baseURL + url;\n",
       "fetch(url).then(function(res) {\n",
       "    if (res.status === 404) {\n",
       "        div.innerHTML = 'Install QIIME 2 Jupyter extension with:<br />' +\n",
       "                        '<code>jupyter serverextension enable --py qiime2' +\n",
       "                        ' --sys-prefix</code><br />then restart your server.' +\n",
       "                        '<br /><br />(Interactive output not available on ' +\n",
       "                        'static notebook viewer services like nbviewer.)';\n",
       "    } else if (res.status === 409) {\n",
       "        div.innerHTML = 'Visualization no longer in scope. Re-run this cell' +\n",
       "                        ' to see the visualization.';\n",
       "    } else if (res.ok) {\n",
       "        url = res.url;\n",
       "        div.innerHTML = '<iframe src=\\'' + url + '\\' style=\\'' +\n",
       "                        'width: 100%; height: 700px; border: 0;\\'>' +\n",
       "                        '</iframe><hr />Open in a: <a href=\\'' + url + '\\'' +\n",
       "                        ' target=\\'_blank\\'>new window</a>'\n",
       "    } else {\n",
       "        div.innerHTML = 'Something has gone wrong. Check notebook server for' +\n",
       "                        ' errors.';\n",
       "    }\n",
       "});\n",
       "})(this.parentElement, '/qiime2/redirect?location=/home/mrobeson/tmp/qiime2-archive-8h2chloj')\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///wAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==\" /></div>"
      ],
      "text/plain": [
       "<visualization: Visualization uuid: 6f95edfd-fc46-4650-b53c-4fc981a9a035>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2.Visualization.load('NR99-proc-steps-evaltax.qzv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mSaved Visualization to: NR99-proc-steps-evalseqs.qzv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "! qiime rescript evaluate-seqs \\\n",
    "    --i-sequences silva-nr99-default-noeuks-noeuks-seqs.qza \\\n",
    "                   silva-nr99-default-noeuks-culled-seqs.qza \\\n",
    "                   silva-nr99-default-noeuks-filt-seqs.qza \\\n",
    "                   silva-nr99-default-noeuks-derep-seqs.qza \\\n",
    "                   silva-nr99-default-noeuks-derep-seqs-gl.qza \\\n",
    "    --p-labels 'Base' 'Culled' 'LengFiltByTax' 'DereplicateUniq' 'NoAmbigLabels' \\\n",
    "    --p-palette 'cividis' \\\n",
    "    --p-subsample-kmers 0.2 \\\n",
    "    --p-kmer-lengths 32 16 8 \\\n",
    "    --o-visualization 'NR99-proc-steps-evalseqs.qzv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><img onload=\"(function(div, url){\n",
       "if (typeof require !== 'undefined') {\n",
       "    var baseURL = require.toUrl('').split('/').slice(0, -2).join('/');\n",
       "} else {\n",
       "    var baseURL = JSON.parse(\n",
       "        document.getElementById('jupyter-config-data').innerHTML\n",
       "    ).baseUrl.slice(0, -1);\n",
       "}\n",
       "url = baseURL + url;\n",
       "fetch(url).then(function(res) {\n",
       "    if (res.status === 404) {\n",
       "        div.innerHTML = 'Install QIIME 2 Jupyter extension with:<br />' +\n",
       "                        '<code>jupyter serverextension enable --py qiime2' +\n",
       "                        ' --sys-prefix</code><br />then restart your server.' +\n",
       "                        '<br /><br />(Interactive output not available on ' +\n",
       "                        'static notebook viewer services like nbviewer.)';\n",
       "    } else if (res.status === 409) {\n",
       "        div.innerHTML = 'Visualization no longer in scope. Re-run this cell' +\n",
       "                        ' to see the visualization.';\n",
       "    } else if (res.ok) {\n",
       "        url = res.url;\n",
       "        div.innerHTML = '<iframe src=\\'' + url + '\\' style=\\'' +\n",
       "                        'width: 100%; height: 700px; border: 0;\\'>' +\n",
       "                        '</iframe><hr />Open in a: <a href=\\'' + url + '\\'' +\n",
       "                        ' target=\\'_blank\\'>new window</a>'\n",
       "    } else {\n",
       "        div.innerHTML = 'Something has gone wrong. Check notebook server for' +\n",
       "                        ' errors.';\n",
       "    }\n",
       "});\n",
       "})(this.parentElement, '/qiime2/redirect?location=/home/mrobeson/tmp/qiime2-archive-1e4c48hj')\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///wAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==\" /></div>"
      ],
      "text/plain": [
       "<visualization: Visualization uuid: d596acc5-d901-4f6c-9d04-5cbb6becf421>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2.Visualization.load('NR99-proc-steps-evalseqs.qzv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validate / fit classifier\n",
    "\n",
    "Run on each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecv_pbs_str2 = \"\"\"#!/bin/bash\n",
    "#PBS -l nodes=1:ppn={ppn},mem={mem},walltime={wt}\n",
    "#PBS -l feature=xeon\n",
    "#PBS -N {job_name}\n",
    "#PBS -o {base_out_path}/{job_name}.out\n",
    "#PBS -e {base_out_path}/{job_name}.err\n",
    "\n",
    "export LC_ALL=en_US.utf-8\n",
    "export LANG=en_US.utf-8\n",
    "\n",
    "source activate qiime2-2020.6\n",
    "\n",
    "date\n",
    "\n",
    "cd {base_out_path}\n",
    "\n",
    "qiime rescript evaluate-cross-validate \\\n",
    "    --i-sequences {base_in_path}/{inseq} \\\n",
    "    --i-taxonomy  {base_in_path}/{intax} \\\n",
    "    --p-n-jobs {ppn} \\\n",
    "    --o-expected-taxonomy {base_out_path}/{exp_tax} \\\n",
    "    --o-observed-taxonomy {base_out_path}/{obs_tax} \\\n",
    "    --o-evaluation {base_out_path}/{eval_tax}\n",
    "\n",
    "date\n",
    "\n",
    "source deactivate\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "efc_pbs_str2 = \"\"\"#!/bin/bash\n",
    "#PBS -l nodes=1:ppn={ppn},mem={mem},walltime={wt}\n",
    "#PBS -l feature=xeon\n",
    "#PBS -N {job_name}\n",
    "#PBS -o {base_out_path}/{job_name}.out\n",
    "#PBS -e {base_out_path}/{job_name}.err\n",
    "\n",
    "export LC_ALL=en_US.utf-8\n",
    "export LANG=en_US.utf-8\n",
    "\n",
    "source activate qiime2-2020.6\n",
    "\n",
    "date\n",
    "\n",
    "cd {base_out_path}\n",
    "\n",
    "qiime rescript evaluate-fit-classifier \\\n",
    "    --i-sequences {base_in_path}/{inseq} \\\n",
    "    --i-taxonomy  {base_in_path}/{intax} \\\n",
    "    --p-n-jobs {ppn} \\\n",
    "    --o-classifier {base_out_path}/{classifier_out_fp} \\\n",
    "    --o-evaluation {base_out_path}/{eval_out_fp} \\\n",
    "    --o-observed-taxonomy {base_out_path}/{obs_tax_out_fp}\n",
    "\n",
    "date\n",
    "\n",
    "source deactivate\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is not a generic function. Written specifically for the output we generated earlier.\n",
    "# Using global string variable `ecv_pbs_str2`\n",
    "def make_ecv_benchmark_pbs_files(ppn = '1',\n",
    "                                 mem = '100GB',\n",
    "                                 wt = '72:00:00',\n",
    "                                 base_in_path = '/home/mrobeson/projects/rescript_benchmarks/ref_dbs/silva-138/silva-138-nr99-default-noeuks',\n",
    "                                 base_out_path = '/home/mrobeson/projects/rescript_benchmarks/ref_dbs/silva-138/silva-138-nr99-default-noeuks',\n",
    "                                 glob_seqs_list = ['silva-nr99-default-noeuks-noeuks-seqs.qza',  'silva-nr99-default-noeuks-culled-seqs.qza',  'silva-nr99-default-noeuks-filt-seqs.qza',  'silva-nr99-default-noeuks-derep-seqs.qza',  'silva-nr99-default-noeuks-derep-seqs-gl.qza']):\n",
    "\n",
    "    chdir(base_in_path)\n",
    "    seq_files = []\n",
    "    for f in glob_seqs_list:\n",
    "        seq_files.extend(glob.glob(f))\n",
    "\n",
    "    tax_files = [sf.replace('seqs', 'taxa') for sf in seq_files]\n",
    "\n",
    "    for s,t in zip(seq_files, tax_files):\n",
    "        bn = path.splitext(t)[0]\n",
    "        job_name = bn + '-ecv'\n",
    "        ecv_str = ecv_pbs_str2.format(ppn = ppn,\n",
    "                   mem = mem,\n",
    "                   wt = wt,\n",
    "                   job_name = job_name,\n",
    "                   base_in_path = base_in_path,\n",
    "                   base_out_path = base_out_path,\n",
    "                   inseq = s,\n",
    "                   intax = t,\n",
    "                   exp_tax = bn + '-ecv-exptax.qza',\n",
    "                   obs_tax = bn + '-ecv-obstax.qza',\n",
    "                   eval_tax = bn + '-ecv-evaltax.qzv')\n",
    "    \n",
    "        job_file_name = job_name + '.pbs'    \n",
    "    \n",
    "        with open(path.join(base_out_path, job_file_name), 'w') as outfile:\n",
    "            outfile.write(ecv_str)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is not a generic function. Written specifically for the output we generated earlier.\n",
    "# Using global string variable `efc_pbs_str2`\n",
    "def make_efc_benchmark_pbs_files(ppn = '1',\n",
    "                        mem = '100GB',\n",
    "                        wt = '72:00:00',\n",
    "                        base_in_path = '/home/mrobeson/projects/rescript_benchmarks/ref_dbs/silva-138/silva-138-nr99-default-noeuks',\n",
    "                        base_out_path = '/home/mrobeson/projects/rescript_benchmarks/ref_dbs/silva-138/silva-138-nr99-default-noeuks',\n",
    "                        glob_seqs_list = ['silva-nr99-default-noeuks-noeuks-seqs.qza',  'silva-nr99-default-noeuks-culled-seqs.qza',  'silva-nr99-default-noeuks-filt-seqs.qza',  'silva-nr99-default-noeuks-derep-seqs.qza',  'silva-nr99-default-noeuks-derep-seqs-gl.qza']):\n",
    "    \n",
    "    chdir(base_in_path)\n",
    "\n",
    "    seq_files = []\n",
    "    for f in glob_seqs_list:\n",
    "        seq_files.extend(glob.glob(f))\n",
    "\n",
    "    tax_files = [sf.replace('seqs', 'taxa') for sf in seq_files]\n",
    "\n",
    "    for s,t in zip(seq_files, tax_files):\n",
    "        bn = path.splitext(t)[0]\n",
    "        job_name = bn + '-efc'\n",
    "        ecv_str = efc_pbs_str2.format(ppn = ppn,\n",
    "                   mem = mem,\n",
    "                   wt = wt,\n",
    "                   job_name = job_name,\n",
    "                   base_in_path = base_in_path,\n",
    "                   base_out_path = base_out_path,\n",
    "                   inseq = s,\n",
    "                   intax = t,\n",
    "                   classifier_out_fp = bn + '-efc-classifier.qza',\n",
    "                   obs_tax_out_fp = bn + '-efc-obstax.qza',\n",
    "                   eval_out_fp = bn + '-efc-evaltax.qzv')\n",
    "    \n",
    "        job_file_name = job_name + '.pbs'    \n",
    "    \n",
    "        with open(path.join(base_out_path, job_file_name), 'w') as outfile:\n",
    "            outfile.write(ecv_str)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_ecv_benchmark_pbs_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_efc_benchmark_pbs_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
